{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a961303",
   "metadata": {},
   "source": [
    "# Question-Answering Demo using Scottish Widows Public Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ccf247-931e-4434-9092-b94a498d5a49",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3403d93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import faiss\n",
    "\n",
    "\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e8fa02-952d-43f0-bd11-789b9d3675ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.preview.language_models import TextGenerationModel, TextEmbeddingModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b408de-d98d-4c60-829b-bdd79c01fc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = ! gcloud config get core/project\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "\n",
    "REGION = \"europe-west2\"\n",
    "\n",
    "PROJECT_ID, REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce297e5-7864-4526-95ef-222760328583",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env PROJECT_ID=$PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d225003c-8712-47d0-8648-95eaecf7bc84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba31ef8c",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Document Source: Based on Scottish Widows' literature library search:\n",
    "https://adviser.scottishwidows.co.uk/literature-library.html\n",
    "\n",
    "Specifically for this demo, the *guides* are selected:\n",
    "https://adviser.scottishwidows.co.uk/literature-library.html?n=1000&filter=swe:literaturelibrary/contenttype/guides\n",
    "\n",
    "The pdf files are scrapped and save in local parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d6080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_guides_file = \"../data/scottish_widows_all_guides.pq\"\n",
    "\n",
    "guides_df = pd.read_parquet(all_guides_file)\n",
    "\n",
    "guides_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa6f0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "guides_df.groupby([\"title\"])[[\"page_number\"]].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2ae797-ba3e-4a4e-89ea-0352419e4f1d",
   "metadata": {},
   "source": [
    "### Remove the blank pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b88f69-0846-4abb-ab70-3d4d263976b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "guides_df = guides_df.loc[guides_df[\"page_text\"]!=\"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc0cfe9",
   "metadata": {},
   "source": [
    "## Embedding using Google's `TextEmbedding` Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7d6d3b",
   "metadata": {},
   "source": [
    "**Approach 1: Using the natural pages as chunks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a417f6b-af69-4c73-812c-b2dd916fb302",
   "metadata": {},
   "outputs": [],
   "source": [
    "guides_df[\"page_text\"].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3c3a2b-8d13-41b7-8826-1671bfe24ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")\n",
    "\n",
    "# return a list of vertexai.language_models._language_models.TextEmbedding\n",
    "#embeddings = model.get_embeddings( [guides_df[\"page_text\"].loc[0]] )\n",
    "embeddings = model.get_embeddings(guides_df[\"page_text\"].loc[0:4]) # maximum 5 instance per embedding!\n",
    "\n",
    "len(embeddings), type(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c292af38-db6f-42c9-975b-81956f967ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for embedding in embeddings:\n",
    "    vector = np.array(embedding.values)\n",
    "    print(vector.shape)\n",
    "    print(vector[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fbe513-b719-43bf-8e35-2e0c46bdca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([embedding.values for embedding in embeddings], name=\"embedding\").to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b454d3-6f57-4458-b6ec-efdf060ec14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_google(se, chunk_size=5):\n",
    "    \"\"\"Using Google's pretrained TextEmbeddingModel to vetorise the series \n",
    "       By default, GCP can process maximum 5 itmes in one go \n",
    "    \"\"\"\n",
    "    model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")\n",
    "    \n",
    "    # generator use to iterate the series over smaller series with chunk_size rows) \n",
    "    small_se_gen = (se.iloc[i:i+chunk_size] for i in range(0, len(se), chunk_size))\n",
    "    small_se_embeddings = [model.get_embeddings(small_se) for small_se in small_se_gen]\n",
    "\n",
    "    eb_list = [\n",
    "        np.array(embedding.values, dtype=\"float32\") \n",
    "        for embeddings in small_se_embeddings \n",
    "        for embedding in embeddings\n",
    "        ]\n",
    "\n",
    "    return pd.Series(eb_list, name=\"embedding\", index=se.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f63a24-8c55-47db-872d-b01289bd9874",
   "metadata": {},
   "source": [
    "**To test the embdding function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dba024-8ddd-410b-8b2b-718fb0735a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one text item each time for the embedding\n",
    "df1 = get_embedding_google(df[\"page_text\"], 1)\n",
    "df1.head(), df1[0][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342d9c41-bede-4e0d-ba4a-00753b13d181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the default chunk size of 5 \n",
    "df2 = get_embedding_google(df[\"page_text\"])\n",
    "df2.head(), df2[0][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7e6fda-8770-4bbc-9e78-1b60c1cb5409",
   "metadata": {},
   "source": [
    "**Note: when more than one piece of text items are send for embedding, the model returns slightly different embeddings vector. But they are very similar when using the dot product to compare!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d4ee44-15c5-4a7a-bd1a-19843d931f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.dot(df2[i], df3[i]) for i, _ in enumerate(df2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a44468-7288-4a2d-a119-3c9f76644264",
   "metadata": {},
   "source": [
    "### Embedding the whole set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6542bed-2ee1-4e4d-9afb-c2a8897ecc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit -n 1 -r 1 # how long does is take? about 1 min for 1000 rows\n",
    "#get_embedding_google(guides_df[\"page_text\"].iloc[0:100])\n",
    "\n",
    "guides_embedded_df = guides_df.assign(\n",
    "    embedding=get_embedding_google(guides_df[\"page_text\"])\n",
    ")\n",
    "guides_embedded_df.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee4a59e-e020-45c1-83a5-499ecb5e572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "guides_embedded_file = \"../data/scottish_widows_all_guides_embedded_v2.pq\"\n",
    "guides_embedded_df.to_parquet(guides_embedded_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070cdf41-40eb-4f88-a6bd-f6de82539f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "guides_df.shape, guides_embedded_df.shape, guides_embedded_df.embedding.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d80520-cfdb-4e0d-a0ec-e039f0327ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81bc5c9f-12e8-48be-ad9d-5837e9d9f79a",
   "metadata": {},
   "source": [
    "## Vector DB using Faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209a2b35-8d58-413c-a634-ecdc0bf6ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "guides_embedded_file = \"../data/scottish_widows_all_guides_embedded_v2.pq\"\n",
    "guides_embedded_df = pd.read_parquet(guides_embedded_file)\n",
    "\n",
    "guides_embedded_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d686d21a-e1fc-4c35-9e3e-4dba6cc114f5",
   "metadata": {},
   "source": [
    "### Assemble the vector array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e663a86-0bb4-4eb2-859d-ecc7a05d497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "guides_embedded_df = guides_embedded_df.reset_index().rename(columns={\"index\": \"id\"}) \n",
    "\n",
    "embedding_array = np.vstack( guides_embedded_df.embedding )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6c18bf-6c9b-41d1-9fd0-2b3be3652408",
   "metadata": {},
   "source": [
    "### Build the vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4ff3bd-df80-4c38-9468-9967eea34af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the index\n",
    "vector_length = guides_embedded_df.embedding[0].size\n",
    "\n",
    "index = faiss.IndexFlatL2(vector_length)\n",
    "\n",
    "# Pass the index to IndexIDMap\n",
    "indexed = faiss.IndexIDMap(index)\n",
    "\n",
    "# Step 4: Add vectors and their IDs\n",
    "indexed.add_with_ids(embedding_array, guides_embedded_df.id.values)\n",
    "\n",
    "print(f\"Number of vectors in the Faiss index: {indexed.ntotal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6972f569",
   "metadata": {},
   "source": [
    "## Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669ed572-ebb1-427f-b367-35725ae43129",
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_page = 3\n",
    "\n",
    "em = embedding_array[pick_page:pick_page+1, :]\n",
    "distances, ids = indexed.search(em, k=3)\n",
    "print(f'L2 distance: {distances[0]}\\nIDs: {ids[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f05378-30c4-4533-842c-0643de9c9fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "guides_embedded_df[ guides_embedded_df.id.isin(ids[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a504293-624a-4c55-87a2-28ae6d9696a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997f00c7-89ca-4a56-8d3a-c2286f88f59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search_google(query, index, num_results=2):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        distances: distances between results and query as float or numpy array.\n",
    "        ids: IDs of the maches as array.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")\n",
    "    \n",
    "    query_vector = np.array(model.get_embeddings([query])[0].values, dtype=\"float32\").reshape(1, -1)\n",
    "\n",
    "    distances, ids = index.search(query_vector, k=num_results)\n",
    "    \n",
    "    return distances, ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4314d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"\"\"\n",
    "How does the Discounted Gift & Income Trust work?\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c254e208",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds, ids = vector_search_google(user_query, indexed, num_results=3)\n",
    "\n",
    "print(f'Euclidean distance: {d[0]}\\nPage IDs: {id[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92309fd-c125-4e2f-afac-13b14248172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the paper titles based on their index\n",
    "guides_embedded_df[ guides_embedded_df[\"id\"].isin(ids[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6858937-a00b-411c-b9c2-448dac06ef43",
   "metadata": {},
   "source": [
    "## Answer the query based on the relevant pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b05ad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = guides_embedded_df[\"page_text\"][ guides_embedded_df[\"id\"].isin(ids[0])].iloc[0]\n",
    "question = \"\"\"How does the Discounted Gift & Income Trust work?\"\"\"\n",
    "\n",
    "template = f\"\"\"You are an expert having a conversation with a user.\n",
    "Given the following extracted parts of a long document and a question,\n",
    "create a final answer. \n",
    "{context}\n",
    "\n",
    "user: {question}\n",
    "expert:\n",
    "\"\"\"\n",
    "\n",
    "parameters = {\n",
    "    \"temperature\": 0.2,\n",
    "    \"max_output_tokens\": 256,   \n",
    "    \"top_p\": .8,                \n",
    "    \"top_k\": 40,                 \n",
    "}\n",
    "\n",
    "model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "response = model.predict(template, **parameters)\n",
    "\n",
    "print(f\"Response from Model: \\n{response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fb35d8-88aa-4a02-abc7-593fecf2abcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512e34c2-9cf2-42d1-96fe-e64d6c1fa7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_text_google(input_text, temperature: float=0.2) -> None:\n",
    "    parameters = {\n",
    "        \"temperature\": temperature,\n",
    "        \"max_output_tokens\": 256,   \n",
    "        \"top_p\": .8,                \n",
    "        \"top_k\": 40,                 \n",
    "    }\n",
    "\n",
    "    model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "    response = model.predict(\n",
    "        input_text,\n",
    "        **parameters,\n",
    "    )\n",
    "    print(f\"Response from Model: \\n{response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c532afe-6db8-4663-8b3e-c5a4ee9cb57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"How does the Discounted Gift & Income Trust work?\"\"\"\n",
    "\n",
    "ds, ids = vector_search_google(question, indexed, num_results=3)\n",
    "\n",
    "context = guides_embedded_df[\"page_text\"][ guides_embedded_df[\"id\"].isin(ids[0])].iloc[0]\n",
    "\n",
    "style = \"a concise way\"\n",
    "#style = \"details\"\n",
    "\n",
    "text = f\"\"\"You are an expert having a conversation with a user.\n",
    "Given the following extracted parts of a long document and a question,\n",
    "create a final answer in {style}. \n",
    "{context}\n",
    "\n",
    "user: {question}\n",
    "expert:\n",
    "\"\"\"\n",
    "\n",
    "gen_text_google(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dc5ddd-8f85-4436-86e0-e9ba58123533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb7f6ea-26a7-48b9-8fc0-011fc6a3cb61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cba5e0a-ad49-4ae8-bff5-4cff8cd50e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e151b763-30da-4c9f-95de-cb8428d4d88e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4966e799-c333-423b-b9c3-5322ff94ff61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ab3a18d-6aca-479d-9b46-c60f21768e60",
   "metadata": {},
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f594d660-3d98-43ea-a902-c47e8c2db1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas DataFrame\n",
    "data = {'name': ['John', 'Jane', 'Mike', 'Susan', 'Peter'],\n",
    "        'age': [20, 25, 30, 35, 40]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d11b01f-6d17-42ef-82ac-eaca73fd0982",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_split(df, 5)\n",
    "#np.array_split(df, 3)\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c6e0de-d892-489b-9f17-0f8aab2882f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first five rows of each DataFrame\n",
    "for df in df_list:\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147ede0c-d9a1-4b47-aa69-1caaae6df66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame( {\n",
    "     'A' : ['foo', 'bar', 'foo', 'bar', 'foo', 'bar', 'foo', 'foo'],\n",
    "     'B' : ['one', 'one', 'two', 'three', 'two', 'two', 'one', 'three'],\n",
    "     'C' : np.random.randn(8), \n",
    "     'D' : np.random.randn(8)}\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdadf19-0587-4c75-a3d8-04857ae1d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_split(df, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2fbdcf-cf3c-4aa4-a17e-61babd0d548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.embedding)//5+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ab31c3-5286-416d-936d-4393ba78a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ =[print(s) for s in np.array_split(df.embedding, len(df.embedding)//5+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72ff32e-fdbd-4d79-b0ba-3ff2e7b99fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a428bce1-dbc1-4453-963f-96635e078eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=5\n",
    "\n",
    "g = (df[\"title\"].iloc[i:i+n] for i in range(0, len(df), n))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cbd74e-a368-45b2-bb84-e2b69ae1fc68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf49023-1edf-4e15-87d2-b3e4b2abcd83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f39021-3f7b-4505-9197-d65438502345",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 5\n",
    "#dd = pd.DataFrame.from_records(guides_embedded_df.embedding) # slow\n",
    "dd = np.vstack( guides_embedded_df.embedding )\n",
    "\n",
    "dd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e21a3e-e52a-4633-89d4-5db1cea05b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06ecbdb-360b-415d-b285-62947c7859ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e93305-894b-4c37-9cf6-e65432e5e0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3]\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8493b3c-6ed5-41f4-9fe4-e9a71abec65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2989479d-93f6-43ea-98cf-73692929a3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")\n",
    "\n",
    "query_vector = np.array(model.get_embeddings([user_query])[0].values, dtype=\"float32\").reshape(1, -1)\n",
    "\n",
    "query_vector.shape\n",
    "D, I = indexed.search(query_vector, k=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24f1047-3b1a-4d9b-81aa-548f4a6a9472",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(query_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c1aaf5-7ab1-46e9-8dfb-87776fbded13",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(query_vector, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386c7ac4-25c9-4c26-92b5-4ca17aed4fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
